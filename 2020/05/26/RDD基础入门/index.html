<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.8.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="Stay foolish, Stay hungry!"><title>RDD基础入门 | Infinity</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/normalize.css/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/purecss/build/pure-min.min.css"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/purecss/build/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.jsdelivr.net/npm/jquery/dist/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><script type="text/javascript" src="//cdn.jsdelivr.net/npm/clipboard/dist/clipboard.min.js"></script><script type="text/javascript" src="//cdn.jsdelivr.net/gh/codeseven/toastr/build/toastr.min.js"></script><link rel="stylesheet" href="//cdn.jsdelivr.net/gh/codeseven/toastr/build/toastr.min.css"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">RDD基础入门</h1><a id="logo" href="/.">Infinity</a><p class="description"></p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">RDD基础入门</h1><div class="post-meta">2020-05-26<span> | </span><span class="category"><a href="/categories/Spark/">Spark</a></span></div><div class="post-content"><h3 id="RDD简介"><a href="#RDD简介" class="headerlink" title="RDD简介"></a>RDD简介</h3><blockquote>
<p>RDD—弹性分布式数据集（Resilient Distributed Dataset）是spark的核心概念。RDD其实就是分布式的元素集合。在Spark中，对数据的所有操作不外乎创建RDD，转化已有的RDD以及调用RDD操作进行求值。而在这一切的背后，spark会自动讲RDD中的数据分发到集群上，并将操作并行化执行。</p>
</blockquote>
<h3 id="RDD基础"><a href="#RDD基础" class="headerlink" title="RDD基础"></a>RDD基础</h3><blockquote>
<p>RDD是一个不可变的分布式对象集合.每个RDD被分为多个分区，这些分区运行在集群中的不同节点上。RDD可以包含Python、Java、Scala中任意类型的对象。</p>
</blockquote>
<p><strong>每个spark程序无外乎都是下面的流程:</strong></p>
<p>1.从外部数据创建输入RDD </p>
<p>2.使用诸如filter()这样的操作对RDD进行转化，定义新的RDD </p>
<p>3.告诉spark对需要被重用的中间RDD执行persisit()操作</p>
<p>4.使用行动操作(count(),first())触发一次并行计算，spark并不会立马执行，而是优化后再执行</p>
<h4 id="1、创建RDD"><a href="#1、创建RDD" class="headerlink" title="1、创建RDD"></a>1、创建RDD</h4><blockquote>
<p>　Spark提供了两种方法创建RDD的方法：</p>
<ul>
<li>读取外部数据集</li>
<li>在驱动器程序中对一个集合进行并行化</li>
</ul>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#parallelize方法将集合转化为rdd</span><br><span class="line">lines = sc.parallelize([&quot;pandas&quot;, &quot;i like pandas&quot;])</span><br><span class="line"></span><br><span class="line">#textFile方法</span><br><span class="line">lines=sc.textFile(&quot;README.md&quot;)</span><br></pre></td></tr></table></figure>
<h4 id="2、RDD操作"><a href="#2、RDD操作" class="headerlink" title="2、RDD操作"></a>2、RDD操作</h4><p><strong>spark支持两种操作：转化操作，行动操作</strong></p>
<h5 id="转化操作"><a href="#转化操作" class="headerlink" title="转化操作"></a>转化操作</h5><blockquote>
<p>转化操作执行时返回新的RDD的操作，转化出来的RDD是惰性求值的，只有在行动中用到这些RDD时才会被计算，许多转化操作只会操作RDD中的一个元素，并不是所有的转化操作都是这样</p>
</blockquote>
<p>比如提取日志文件的错误信息</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">inputRDD=sc.testFile(&quot;log.txt&quot;)</span><br><span class="line">errorsRDD=inputRDD.filter(lambda x:&quot;error&quot; in x)</span><br><span class="line">warningsRDD = inputRDD.filter(lambda x: &quot;warning&quot; in x)</span><br><span class="line"># 将errorsRDD和warningsRDD合并成一个RDD</span><br><span class="line">badLinesRDD = errorsRDD.union(warningsRDD)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>通过转化操作，从已有的RDD中派生新的RDD，spark会使用谱系图记录这些RDD的依赖关系，spark在需要用这些信息的时候按需计算每个RDD，也可以依靠谱系图在丢失数据的情况下恢复丢失的数据</p>
</blockquote>
<h5 id="行动操作"><a href="#行动操作" class="headerlink" title="行动操作"></a>行动操作</h5><blockquote>
<p>行动操作需要实际的输出，它会强制执行哪些求值必须用到的RDD转化操作 </p>
</blockquote>
<p>示例：对badLinesRDD进行计数操作，并且打印前十条记录</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">print &quot;Input had &quot; + badLinesRDD.count() + &quot; concerning lines&quot;</span><br><span class="line"># take(num) 从RDD中取出num个元素</span><br><span class="line">for line in badLinesRDD.take(10):</span><br><span class="line">    print line</span><br></pre></td></tr></table></figure>
<blockquote>
<p>这里使用了take()取出少量的数据集，也可以使用collect()函数获取整个RDD中的数据，但是使用collect需要注意内存是否够用。如果数据集特别大的时候，我们需要把数据写到诸如HDFS之类的分布式存储系统，当调用一个新的行动操作的时候整个RDD会从头计算，我们要将中间结果持久化</p>
</blockquote>
<h5 id="惰性求值"><a href="#惰性求值" class="headerlink" title="惰性求值"></a>惰性求值</h5><blockquote>
<p>RDD的转化操作都是多心求值的，这意味着在被调用行动操作之前Spark不会开始计算。</p>
<p>惰性求值意味着我们对RDD调用转化操作（例如map()）时，操作不会立即执行，相反，Spark会在内部记录下所要求执行的操作的相关信息。<strong>我们不应该把RDD看作放着特定数据的数据集，而最好把每个RDD看作我们通过转化操作构建出来的、记录如何计算数据的指令列表</strong>。把数据读到RDD的操作也是惰性的，因此，当我们调用sc.textFile()时，数据并没有读取进来，而是在必要时才会读取。</p>
</blockquote>
<h4 id="3、函数传递"><a href="#3、函数传递" class="headerlink" title="3、函数传递"></a>3、函数传递</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#使用lambda方法传递</span><br><span class="line">word = rdd.filter(lambda s: &quot;error&quot; in s)</span><br><span class="line"></span><br><span class="line">#定义一个函数然后传递</span><br><span class="line">def containsError(s):</span><br><span class="line">    return &quot;error&quot; in s</span><br><span class="line">word = rdd.filter(containsError)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>传递函数时要小心，python会在不经意间把函数所在的对象也序列化传出，有时如果传递的类里包含了python不知道如何序列化输出的对象，也可能导致程序失败。</p>
<p>如下是一个错误的函数传递示例；</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">class SearchFunctions(object):</span><br><span class="line">    def __init__(self, query):</span><br><span class="line">        self.query = query</span><br><span class="line">    def isMatch(self, s):</span><br><span class="line">        return self.query in s</span><br><span class="line">    def getMatchesFunctionReference(self, rdd):</span><br><span class="line">        # 问题：在&quot;self.isMatch&quot;中引用了整个self</span><br><span class="line">        return rdd.filter(self.isMatch)</span><br><span class="line">    def getMatchesMemberReference(self, rdd):</span><br><span class="line">        # 问题：在&quot;self.query&quot;中引用了整个self</span><br><span class="line">        return rdd.filter(lambda x: self.query in x)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>正确做法:</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">class WordFunctions(object):</span><br><span class="line">    def getMatchesNoReference(self, rdd):</span><br><span class="line">        # 安全：只把需要的字段提取到局部变量中</span><br><span class="line">        query = self.query</span><br><span class="line">        return rdd.filter(lambda x: query in x)</span><br></pre></td></tr></table></figure>
<h4 id="4、RDD操作"><a href="#4、RDD操作" class="headerlink" title="4、RDD操作"></a>4、RDD操作</h4><blockquote>
<p>常见的转化操作</p>
</blockquote>
<p><img src="https://markdown-1258220306.cos.ap-shenzhen-fsi.myqcloud.com/img/rdd1.png" alt=""></p>
<p><img src="https://markdown-1258220306.cos.ap-shenzhen-fsi.myqcloud.com/img/rdd2.png" alt=""></p>
<blockquote>
<p>常见的行动操作</p>
</blockquote>
<p><img src="https://markdown-1258220306.cos.ap-shenzhen-fsi.myqcloud.com/img/rdd3.png" alt=""></p>
<h4 id="5、持久化-缓存"><a href="#5、持久化-缓存" class="headerlink" title="5、持久化(缓存)"></a>5、持久化(缓存)</h4><blockquote>
<p>如前所述， Spark<br>RDD是惰性求值的，而有时我们希望能多次使用同一个 RDD。如果简单<br>地对 RDD 调用行动操作， Spark 每次都会重算 RDD 以及它的所有依赖。这在迭代算法中<br>消耗格外大，因为迭代算法常常会多次使用同一组数据。</p>
<p>如下就是先对 RDD 作一次计数、再把该 RDD 输出的一个小例子。</p>
</blockquote>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> result = input.map(x =&gt; x*x)</span><br><span class="line">println(result.count())</span><br><span class="line">println(result.collect().mkString(<span class="string">","</span>))</span><br></pre></td></tr></table></figure>
<blockquote>
<p>为了避免多次计算同一个 RDD，可以让 Spark 对数据进行持久化。当我们让 Spark 持久化<br>存储一个 RDD 时，计算出 RDD 的节点会分别保存它们所求出的分区数据。如果一个有持<br>久化数据的节点发生故障， Spark 会在需要用到缓存的数据时重算丢失的数据分区。如果<br>希望节点故障的情况不会拖累我们的执行速度，也可以把数据备份到多个节点上。</p>
<p>出于不同的目的，我们可以为 RDD 选择不同的持久化级别（如表 3-6 所示）。在 Scala和 Java 中，默认情况下 persist() 会把数据以序列化的形式缓存在 JVM 的堆空<br>间中。在 Python 中，我们会始终序列化要持久化存储的数据，所以持久化级别默认值就是<br>以序列化后的对象存储在 JVM 堆空间中。当我们把数据写到磁盘或者堆外存储上时，也<br>总是使用序列化后的数据。</p>
</blockquote>
<p><img src="https://markdown-1258220306.cos.ap-shenzhen-fsi.myqcloud.com/img/rdd4.png" alt=""></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> result = input.map(x =&gt; x * x)</span><br><span class="line">result.persist(<span class="type">StorageLevel</span>.<span class="type">DISK_ONLY</span>)</span><br><span class="line">println(result.count())</span><br><span class="line">println(result.collect().mkString(<span class="string">","</span>))</span><br></pre></td></tr></table></figure>
<blockquote>
<p>如果要缓存的数据太多， 内存中放不下， Spark 会自动利用最近最少使用（ LRU）的缓存<br>策略把最老的分区从内存中移除。 对于仅把数据存放在内存中的缓存级别，下一次要用到<br>已经被移除的分区时， 这些分区就需要重新计算。但是对于使用内存与磁盘的缓存级别的<br>分区来说，被移除的分区都会写入磁盘。不论哪一种情况，都不必担心你的作业因为缓存<br>了太多数据而被打断。 不过，缓存不必要的数据会导致有用的数据被移出内存，带来更多<br>重算的时间开销</p>
</blockquote>
</div><div class="tags"><a href="/tags/Spark/"><i class="fa fa-tag"></i>Spark</a></div><div class="post-nav"><a class="pre" href="/2020/05/26/RDD算子总结/">RDD算子总结</a><a class="next" href="/2020/05/26/MapReduce/">MapReduce介绍</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"><input type="hidden" name="sitesearch" value="shu-howting.github.io"></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Spark/">Spark</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/">机器学习</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/Spark技术/" style="font-size: 15px;">Spark技术</a> <a href="/tags/Spark/" style="font-size: 15px;">Spark</a> <a href="/tags/推荐算法/" style="font-size: 15px;">推荐算法</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2020/05/26/repartition和coalesce区别/">repartition和coalesce区别</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/05/26/关于Spark运行中内存超出的问题/">Spark运行内存超出</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/05/26/Spark性能调优：合理设置并行度/">Spark并行度理解</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/05/26/spark中的各种概念的理解/">Spark中的各种概念</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/05/26/cache算子和persist算子/">cache和persist比较</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/05/26/RDD算子总结/">RDD算子总结</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/05/26/RDD基础入门/">RDD基础入门</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/05/26/MapReduce/">MapReduce介绍</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/05/26/spark2.0的新特性/">Spark2.0的新特性</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/08/29/spark入门/">Spark生态介绍</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://www.example1.com/" title="site-name1" target="_blank">site-name1</a><ul></ul><a href="http://www.example2.com/" title="site-name2" target="_blank">site-name2</a><ul></ul><a href="http://www.example3.com/" title="site-name3" target="_blank">site-name3</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2020 <a href="/." rel="nofollow">Infinity.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.jsdelivr.net/gh/fancyapps/fancybox/dist/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox/dist/jquery.fancybox.min.css"><script type="text/javascript" src="/js/copycode.js" successtext="复制成功!"></script><link rel="stylesheet" type="text/css" href="/css/copycode.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>