<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[RDD入门]]></title>
    <url>%2F2019%2F08%2F29%2Fspark%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[生态： Spark Core：包含Spark的基本功能；尤其是定义RDD的API、操作以及这两者上的动作。其他Spark的库都是构建在RDD和Spark Core之上的 Spark SQL：提供通过Apache Hive的SQL变体Hive查询语言（HiveQL）与Spark进行交互的API。每个数据库表被当做一个RDD，Spark SQL查询被转换为Spark操作。 Spark Streaming：对实时数据流进行处理和控制。Spark Streaming允许程序能够像普通RDD一样处理实时数据 MLlib：一个常用机器学习算法库，算法被实现为对RDD的Spark操作。这个库包含可扩展的学习算法，比如分类、回归等需要对大量数据集进行迭代的操作。 GraphX：控制图、并行图操作和计算的一组算法和工具的集合。GraphX扩展了RDD API，包含控制图、创建子图、访问路径上所有顶点的操作 架构： Cluster Manager：在standalone模式中即为Master主节点，控制整个集群，监控worker。在YARN模式中为资源管理器 Worker节点：从节点，负责控制计算节点，启动Executor或者Driver。 Driver： 运行Application 的main()函数 Executor：执行器，是为某个Application运行在worker node上的一个进程 术语： Application: Appliction都是指用户编写的Spark应用程序，其中包括一个Driver功能的代码和分布在集群中多个节点上运行的Executor代码 Driver: Spark中的Driver即运行上述Application的main函数并创建SparkContext，创建SparkContext的目的是为了准备Spark应用程序的运行环境，在Spark中有SparkContext负责与ClusterManager通信，进行资源申请、任务的分配和监控等，当Executor部分运行完毕后，Driver同时负责将SparkContext关闭，通常用SparkContext代表Driver Executor: 某个Application运行在worker节点上的一个进程， 该进程负责运行某些Task， 并且负责将数据存到内存或磁盘上，每个Application都有各自独立的一批Executor， 在Spark on Yarn模式下，其进程名称为CoarseGrainedExecutor Backend。一个CoarseGrainedExecutor Backend有且仅有一个Executor对象， 负责将Task包装成taskRunner,并从线程池中抽取一个空闲线程运行Task， 这个每一个oarseGrainedExecutor Backend能并行运行Task的数量取决与分配给它的cpu个数 Cluter Manager：指的是在集群上获取资源的外部服务。目前有三种类型 Standalon : spark原生的资源管理，由Master负责资源的分配 Apache Mesos:与hadoop MR兼容性良好的一种资源调度框架 Hadoop Yarn: 主要是指Yarn中的ResourceManager Worker: 集群中任何可以运行Application代码的节点，在Standalone模式中指的是通过slave文件配置的Worker节点，在Spark on Yarn模式下就是NoteManager节点 Task: 被送到某个Executor上的工作单元，但hadoopMR中的MapTask和ReduceTask概念一样，是运行Application的基本单位，多个Task组成一个Stage，而Task的调度和管理等是由TaskScheduler负责 Job: 包含多个Task组成的并行计算，往往由Spark Action触发生成， 一个Application中往往会产生多个Job Stage: 每个Job会被拆分成多组Task， 作为一个TaskSet， 其名称为Stage，Stage的划分和调度是有DAGScheduler来负责的，Stage有非最终的Stage（Shuffle Map Stage）和最终的Stage（Result Stage）两种，Stage的边界就是发生shuffle的地方]]></content>
      <categories>
        <category>Spark</category>
      </categories>
      <tags>
        <tag>Spark技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[推荐算法]]></title>
    <url>%2F2018%2F12%2F05%2F%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[推荐算法 基于内容的推荐算法 根据物品或内容的元数据，发现商品或内容的相关性，然后根据用户之前的喜好记录，推荐相似的物品 如：用户X购买过商品A，而A和B是相似的（iphone和小米手机），就可以把B推荐给X 协同过滤基于物品的协同过滤(Item-based Collaborative Filtering)首先从数据库里获取所有用户对物品的评价，根据评价，计算物品的相似度。然后从剩下的物品中找到和他历史兴趣近似的物品推荐给他。核心是要计算两个物品的相似度。基于用户的协同过滤(Item-based Collaborative Filtering)，基于用户的协同过滤推荐算法先使用统计技术寻找与目标用户有相同喜好的邻居，然后根据目标用户的邻居的喜好产生向目标用户的推荐。基本原理就是利用用户访问行为的相似性来互相推荐用户可能感兴趣的资源，区别： 可以注意到,基于物品的协同过滤和基于内容的推荐，两者的相同点都是要计算两个物品的相似度，但不同点是前者是根据两个物品被越多的人同时喜欢，这两个物品就越相似，而后者要根据物品的内容相似度来做推荐，给物品内容建模的方法很多，最著名的是向量空间模型，要计算两个向量的相似度。由此可以看到两种方法的不同点在于计算两个物品的相似度方法不同，一个根据外界环境计算，一个根据内容计算。 综上： 基于内容的推荐，只考虑了对象的本身性质，将对象按标签形成集合，如果你消费集合中的一个则向你推荐集合中的其他对象； 基于协调过滤，充分利用集体智慧，即在大量的人群的行为和数据中收集答案，以帮助我们对整个人群得到统计意义上的结论，推荐的个性化程度高，基于以下两个出发点： (1)兴趣相近的用户可能会对同样的东西感兴趣； (2)用户可能较偏爱与其已购买的东西相类似的商品。 也就是说考虑进了用户的历史习惯，对象客观上不一定相似，但由于人的行为可以认为其主观上是相似的，就可以产生推荐了。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>推荐算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[first_blog]]></title>
    <url>%2F2018%2F12%2F03%2Ffirst-blog%2F</url>
    <content type="text"><![CDATA[测试第一遍新建的blog mac blog 测试 –by hexo 哈哈我成功了测试]]></content>
      <categories>
        <category>test</category>
      </categories>
      <tags>
        <tag>blog</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2018%2F12%2F03%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
